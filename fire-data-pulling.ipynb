{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22416899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d81d37",
   "metadata": {},
   "source": [
    "# Wildfire Spread Prediction Feature Descriptions\n",
    "\n",
    "| Feature Key  | Description |\n",
    "|-------------|-------------|\n",
    "| `vs`       | **Wind Speed** (m/s) – Measures how fast the wind is moving, affecting fire spread. |\n",
    "| `th`       | **Theta (Potential Temperature)** – Represents the temperature an air parcel would have if moved adiabatically to a standard pressure level. |\n",
    "| `population` | **Population Density** – Indicates how many people live in a given area, affecting fire risk and response strategies. |\n",
    "| `tmmx`     | **Maximum Daily Temperature** (°C) – The highest temperature recorded during the day. |\n",
    "| `PrevFireMask` | **Previous Fire Presence** (Binary/Mask) – Indicates if there was fire in the area the day before. |\n",
    "| `elevation` | **Elevation** (meters) – The height above sea level, affecting weather conditions and fire behavior. |\n",
    "| `sph`      | **Specific Humidity** (kg/kg) – The amount of water vapor per unit of air mass, influencing fuel moisture. |\n",
    "| `pr`       | **Precipitation** (mm) – The amount of rainfall, which can suppress fire spread. |\n",
    "| `pdsi`     | **Palmer Drought Severity Index (PDSI)** – A measure of drought conditions, with lower values indicating more severe drought. |\n",
    "| `erc`      | **Energy Release Component (ERC)** – A fire weather index estimating the potential available energy in live and dead fuels. |\n",
    "| `FireMask` | **Current Fire Presence** (Binary/Mask) – Indicates if there is an active fire in the area. |\n",
    "| `NDVI`     | **Normalized Difference Vegetation Index (NDVI)** – A measure of vegetation health, where higher values indicate lush greenery and lower values indicate dry or dead vegetation. |\n",
    "| `tmmn`     | **Minimum Daily Temperature** (°C) – The lowest temperature recorded during the day. |\n",
    "\n",
    "---\n",
    "\n",
    "### Why These Features Matter for Fire Spread Prediction\n",
    "- **Temperature (`tmmx`, `tmmn`)**: Higher temperatures dry out vegetation, making it more flammable.\n",
    "- **Humidity (`sph`)**: Lower humidity means drier conditions, increasing fire risk.\n",
    "- **Wind Speed (`vs`)**: Stronger winds accelerate fire spread and can change fire direction unpredictably.\n",
    "- **Precipitation (`pr`)**: Rainfall can suppress fire ignition and spread.\n",
    "- **Drought Index (`pdsi`)**: Long-term dryness can make regions more susceptible to wildfires.\n",
    "- **Energy Release Component (`erc`)**: Higher ERC values indicate more available fuel energy, leading to more intense fires.\n",
    "- **Vegetation Health (`NDVI`)**: Green vegetation retains moisture, while dry vegetation is more flammable.\n",
    "- **Elevation (`elevation`)**: Fires behave differently at higher altitudes due to changes in oxygen levels and terrain.\n",
    "- **Fire Mask Features (`FireMask`, `PrevFireMask`)**: Indicate whether there were past or present wildfires in a given area, helping models track fire movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3442e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['NDVI', 'tmmn', 'elevation', 'population', 'FireMask', 'vs', 'pdsi', 'pr', 'tmmx', 'sph', 'th', 'PrevFireMask', 'erc']\n",
      "Feature Schema: {'NDVI': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'tmmn': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'elevation': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'population': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'FireMask': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'vs': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'pdsi': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'pr': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'tmmx': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'sph': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'th': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'PrevFireMask': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'erc': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 17:27:32.199029: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:370] TFRecordDataset `buffer_size` is unspecified, default to 262144\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define dataset file paths\n",
    "tfrecord_dir = \"data/\"\n",
    "\n",
    "def get_tfrecord_files(prefix):\n",
    "    return sorted([os.path.join(tfrecord_dir, f) for f in os.listdir(tfrecord_dir) if f.startswith(prefix)])\n",
    "\n",
    "# Automatically get all train, eval, and test files\n",
    "train_tfrecord_files = get_tfrecord_files(\"next_day_wildfire_spread_train_\")\n",
    "eval_tfrecord_files = get_tfrecord_files(\"next_day_wildfire_spread_eval_\")\n",
    "test_tfrecord_files = get_tfrecord_files(\"next_day_wildfire_spread_test_\")\n",
    "\n",
    "# Load first record to check feature structure\n",
    "def get_feature_names(tfrecord_files):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    for raw_record in raw_dataset.take(1):  # Take first record\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        return list(example.features.feature.keys())  # Extract feature names\n",
    "\n",
    "feature_names = get_feature_names(train_tfrecord_files)\n",
    "print(\"Feature Names:\", feature_names)\n",
    "\n",
    "def get_feature_schema(tfrecord_file):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    for raw_record in raw_dataset.take(1):  # Inspect first record\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        schema = {}\n",
    "        for key, feature in example.features.feature.items():\n",
    "            dtype = feature.WhichOneof(\"kind\")\n",
    "            if dtype == \"float_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([len(feature.float_list.value)], tf.float32)\n",
    "            elif dtype == \"int64_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([len(feature.int64_list.value)], tf.int64)\n",
    "            elif dtype == \"bytes_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([], tf.string)\n",
    "        return schema\n",
    "\n",
    "feature_schema = get_feature_schema(train_tfrecord_files[0])\n",
    "print(\"Feature Schema:\", feature_schema)\n",
    "\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_schema)\n",
    "    \n",
    "    # Assuming each feature is a 64x64 grid, reshape accordingly\n",
    "    cnn_input = tf.stack([\n",
    "        tf.reshape(parsed_features['FireMask'], [64, 64]),\n",
    "        tf.reshape(parsed_features['NDVI'], [64, 64]),\n",
    "        tf.reshape(parsed_features['PrevFireMask'], [64, 64])\n",
    "    ], axis=-1)  # Shape: (64, 64, 3)\n",
    "\n",
    "    # No LSTM input needed for spatial data\n",
    "    dense_input = tf.stack([parsed_features['vs'], parsed_features['tmmx'], parsed_features['tmmn']], axis=-1)\n",
    "    \n",
    "    # Reshape target to match model output\n",
    "    target = tf.reduce_mean(parsed_features['FireMask'])  # Example: reduce to a single value\n",
    "\n",
    "    return {'cnn_input': cnn_input, 'dense_input': dense_input}, target\n",
    "\n",
    "def load_dataset(filenames, batch_size=32):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(parse_tfrecord_fn)\n",
    "    dataset = dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = load_dataset(train_tfrecord_files)\n",
    "eval_dataset = load_dataset(eval_tfrecord_files)\n",
    "test_dataset = load_dataset(test_tfrecord_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ad41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sydneybalboni/Documents/GitHub/fire-research/.venv/lib/python3.12/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: cnn_input\n",
      "Received: inputs=['Tensor(shape=(None, 64, 64, 3))']\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.0547 - loss: 0.0203\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 17:28:27.953746: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Users/sydneybalboni/Documents/GitHub/fire-research/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0562 - loss: 0.0133\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 17:28:38.395964: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.0582 - loss: 0.0140\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0629 - loss: 0.0144\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 17:28:59.021065: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0564 - loss: 0.0136\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0582 - loss: 0.0129\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0554 - loss: 0.0137\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0574 - loss: 0.0122\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 17:29:40.326740: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0569 - loss: 0.0135\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0553 - loss: 0.0140\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0563 - loss: 0.0133\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0540 - loss: 0.0138\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.0557 - loss: 0.0136\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.0538 - loss: 0.0140\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0555 - loss: 0.0134\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.0575 - loss: 0.0123\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 17:31:04.096483: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.0551 - loss: 0.0129\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.0567 - loss: 0.0140\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.0584 - loss: 0.0133\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.0545 - loss: 0.0134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13e5e3170>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Define CNN Model\n",
    "cnn_input = Input(shape=(64, 64, 3), name=\"cnn_input\")  # Adjust shape based on your data\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\")(cnn_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=cnn_input, outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa2f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0469 - loss: 0.0112\n",
      "Evaluation Loss: 0.014339993707835674, Evaluation Accuracy: 0.0506126806139946\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0497 - loss: 0.0149\n",
      "Test Loss: 0.016004350036382675, Test Accuracy: 0.05269390344619751\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_loss, eval_accuracy = model.evaluate(eval_dataset)\n",
    "print(f\"Evaluation Loss: {eval_loss}, Evaluation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
