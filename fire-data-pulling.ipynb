{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22416899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d81d37",
   "metadata": {},
   "source": [
    "# Wildfire Spread Prediction Feature Descriptions\n",
    "\n",
    "| Feature Key  | Description |\n",
    "|-------------|-------------|\n",
    "| `vs`       | **Wind Speed** (m/s) – Measures how fast the wind is moving, affecting fire spread. |\n",
    "| `th`       | **Theta (Potential Temperature)** – Represents the temperature an air parcel would have if moved adiabatically to a standard pressure level. |\n",
    "| `population` | **Population Density** – Indicates how many people live in a given area, affecting fire risk and response strategies. |\n",
    "| `tmmx`     | **Maximum Daily Temperature** (°C) – The highest temperature recorded during the day. |\n",
    "| `PrevFireMask` | **Previous Fire Presence** (Binary/Mask) – Indicates if there was fire in the area the day before. |\n",
    "| `elevation` | **Elevation** (meters) – The height above sea level, affecting weather conditions and fire behavior. |\n",
    "| `sph`      | **Specific Humidity** (kg/kg) – The amount of water vapor per unit of air mass, influencing fuel moisture. |\n",
    "| `pr`       | **Precipitation** (mm) – The amount of rainfall, which can suppress fire spread. |\n",
    "| `pdsi`     | **Palmer Drought Severity Index (PDSI)** – A measure of drought conditions, with lower values indicating more severe drought. |\n",
    "| `erc`      | **Energy Release Component (ERC)** – A fire weather index estimating the potential available energy in live and dead fuels. |\n",
    "| `FireMask` | **Current Fire Presence** (Binary/Mask) – Indicates if there is an active fire in the area. |\n",
    "| `NDVI`     | **Normalized Difference Vegetation Index (NDVI)** – A measure of vegetation health, where higher values indicate lush greenery and lower values indicate dry or dead vegetation. |\n",
    "| `tmmn`     | **Minimum Daily Temperature** (°C) – The lowest temperature recorded during the day. |\n",
    "\n",
    "---\n",
    "\n",
    "### Why These Features Matter for Fire Spread Prediction\n",
    "- **Temperature (`tmmx`, `tmmn`)**: Higher temperatures dry out vegetation, making it more flammable.\n",
    "- **Humidity (`sph`)**: Lower humidity means drier conditions, increasing fire risk.\n",
    "- **Wind Speed (`vs`)**: Stronger winds accelerate fire spread and can change fire direction unpredictably.\n",
    "- **Precipitation (`pr`)**: Rainfall can suppress fire ignition and spread.\n",
    "- **Drought Index (`pdsi`)**: Long-term dryness can make regions more susceptible to wildfires.\n",
    "- **Energy Release Component (`erc`)**: Higher ERC values indicate more available fuel energy, leading to more intense fires.\n",
    "- **Vegetation Health (`NDVI`)**: Green vegetation retains moisture, while dry vegetation is more flammable.\n",
    "- **Elevation (`elevation`)**: Fires behave differently at higher altitudes due to changes in oxygen levels and terrain.\n",
    "- **Fire Mask Features (`FireMask`, `PrevFireMask`)**: Indicate whether there were past or present wildfires in a given area, helping models track fire movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3442e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['NDVI', 'tmmn', 'elevation', 'population', 'FireMask', 'vs', 'pdsi', 'pr', 'tmmx', 'sph', 'th', 'PrevFireMask', 'erc']\n"
     ]
    }
   ],
   "source": [
    "# Define dataset file paths\n",
    "tfrecord_dir = \"data/\"\n",
    "tfrecord_files = [\n",
    "    tfrecord_dir + fname for fname in [\n",
    "        \"next_day_wildfire_spread_train_00.tfrecord\", \"next_day_wildfire_spread_train_01.tfrecord\",\n",
    "        \"next_day_wildfire_spread_train_02.tfrecord\", \"next_day_wildfire_spread_train_03.tfrecord\",\n",
    "        \"next_day_wildfire_spread_train_04.tfrecord\", \"next_day_wildfire_spread_train_05.tfrecord\",\n",
    "        \"next_day_wildfire_spread_train_06.tfrecord\", \"next_day_wildfire_spread_train_07.tfrecord\",\n",
    "        \"next_day_wildfire_spread_train_08.tfrecord\", \"next_day_wildfire_spread_train_09.tfrecord\",\n",
    "        \"next_day_wildfire_spread_train_10.tfrecord\", \"next_day_wildfire_spread_train_11.tfrecord\",\n",
    "        \"next_day_wildfire_spread_train_12.tfrecord\", \"next_day_wildfire_spread_train_13.tfrecord\",\n",
    "        \"next_day_wildfire_spread_train_14.tfrecord\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Load first record to check feature structure\n",
    "def get_feature_names(tfrecord_files):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    for raw_record in raw_dataset.take(1):  # Take first record\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        return list(example.features.feature.keys())  # Extract feature names\n",
    "\n",
    "feature_names = get_feature_names(tfrecord_files)\n",
    "print(\"Feature Names:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba44a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Schema: {'NDVI': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'tmmn': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'elevation': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'population': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'FireMask': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'vs': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'pdsi': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'pr': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'tmmx': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'sph': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'th': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'PrevFireMask': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'erc': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None)}\n"
     ]
    }
   ],
   "source": [
    "def get_feature_schema(tfrecord_file):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    for raw_record in raw_dataset.take(1):  # Inspect first record\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        \n",
    "        schema = {}\n",
    "        for key, feature in example.features.feature.items():\n",
    "            dtype = feature.WhichOneof(\"kind\")\n",
    "            if dtype == \"float_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([len(feature.float_list.value)], tf.float32)\n",
    "            elif dtype == \"int64_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([len(feature.int64_list.value)], tf.int64)\n",
    "            elif dtype == \"bytes_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([], tf.string)\n",
    "        return schema\n",
    "\n",
    "feature_schema = get_feature_schema(tfrecord_files[0])\n",
    "print(\"Feature Schema:\", feature_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddadcf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example_proto):\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_schema)\n",
    "    \n",
    "    # Assuming each feature is a 64x64 grid, reshape accordingly\n",
    "    cnn_input = tf.stack([\n",
    "        tf.reshape(parsed_features['FireMask'], [64, 64]),\n",
    "        tf.reshape(parsed_features['NDVI'], [64, 64]),\n",
    "        tf.reshape(parsed_features['PrevFireMask'], [64, 64])\n",
    "    ], axis=-1)  # Shape: (64, 64, 3)\n",
    "\n",
    "    # No LSTM input needed for spatial data\n",
    "    dense_input = tf.stack([parsed_features['vs'], parsed_features['tmmx'], parsed_features['tmmn']], axis=-1)\n",
    "    \n",
    "    # Reshape target to match model output\n",
    "    target = tf.reduce_mean(parsed_features['FireMask'])  # Example: reduce to a single value\n",
    "\n",
    "    return {'cnn_input': cnn_input, 'dense_input': dense_input}, target\n",
    "\n",
    "\n",
    "def load_dataset(filenames, batch_size=32):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(parse_tfrecord_fn)\n",
    "    dataset = dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load training, evaluation, and test sets\n",
    "train_dataset = load_dataset(tfrecord_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ad41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0508 - loss: 0.1274\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0522 - loss: 0.0117\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0547 - loss: 0.0128\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0535 - loss: 0.0140\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0602 - loss: 0.0139\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0580 - loss: 0.0142\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0556 - loss: 0.0148\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 11:10:31.899281: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0563 - loss: 0.0136\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0544 - loss: 0.0134\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.0567 - loss: 0.0132\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.0569 - loss: 0.0143\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0543 - loss: 0.0125\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0571 - loss: 0.0133\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.0555 - loss: 0.0141\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0569 - loss: 0.0141\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0545 - loss: 0.0136\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0584 - loss: 0.0125\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0554 - loss: 0.0142\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0595 - loss: 0.0140\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.0551 - loss: 0.0130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13a797f20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Load training dataset\n",
    "train_dataset = load_dataset(tfrecord_files)\n",
    "\n",
    "# Define CNN Model\n",
    "cnn_input = Input(shape=(64, 64, 3), name=\"cnn_input\")  # Adjust shape based on your data\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\")(cnn_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=cnn_input, outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa2f67a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mtest_dataset\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea205460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
