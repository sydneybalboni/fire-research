{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22416899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d81d37",
   "metadata": {},
   "source": [
    "# Wildfire Spread Prediction Feature Descriptions\n",
    "\n",
    "| Feature Key  | Description |\n",
    "|-------------|-------------|\n",
    "| `vs`       | **Wind Speed** (m/s) – Measures how fast the wind is moving, affecting fire spread. |\n",
    "| `th`       | **Theta (Potential Temperature)** – Represents the temperature an air parcel would have if moved adiabatically to a standard pressure level. |\n",
    "| `population` | **Population Density** – Indicates how many people live in a given area, affecting fire risk and response strategies. |\n",
    "| `tmmx`     | **Maximum Daily Temperature** (°C) – The highest temperature recorded during the day. |\n",
    "| `PrevFireMask` | **Previous Fire Presence** (Binary/Mask) – Indicates if there was fire in the area the day before. |\n",
    "| `elevation` | **Elevation** (meters) – The height above sea level, affecting weather conditions and fire behavior. |\n",
    "| `sph`      | **Specific Humidity** (kg/kg) – The amount of water vapor per unit of air mass, influencing fuel moisture. |\n",
    "| `pr`       | **Precipitation** (mm) – The amount of rainfall, which can suppress fire spread. |\n",
    "| `pdsi`     | **Palmer Drought Severity Index (PDSI)** – A measure of drought conditions, with lower values indicating more severe drought. |\n",
    "| `erc`      | **Energy Release Component (ERC)** – A fire weather index estimating the potential available energy in live and dead fuels. |\n",
    "| `FireMask` | **Current Fire Presence** (Binary/Mask) – Indicates if there is an active fire in the area. |\n",
    "| `NDVI`     | **Normalized Difference Vegetation Index (NDVI)** – A measure of vegetation health, where higher values indicate lush greenery and lower values indicate dry or dead vegetation. |\n",
    "| `tmmn`     | **Minimum Daily Temperature** (°C) – The lowest temperature recorded during the day. |\n",
    "\n",
    "---\n",
    "\n",
    "### Why These Features Matter for Fire Spread Prediction\n",
    "- **Temperature (`tmmx`, `tmmn`)**: Higher temperatures dry out vegetation, making it more flammable.\n",
    "- **Humidity (`sph`)**: Lower humidity means drier conditions, increasing fire risk.\n",
    "- **Wind Speed (`vs`)**: Stronger winds accelerate fire spread and can change fire direction unpredictably.\n",
    "- **Precipitation (`pr`)**: Rainfall can suppress fire ignition and spread.\n",
    "- **Drought Index (`pdsi`)**: Long-term dryness can make regions more susceptible to wildfires.\n",
    "- **Energy Release Component (`erc`)**: Higher ERC values indicate more available fuel energy, leading to more intense fires.\n",
    "- **Vegetation Health (`NDVI`)**: Green vegetation retains moisture, while dry vegetation is more flammable.\n",
    "- **Elevation (`elevation`)**: Fires behave differently at higher altitudes due to changes in oxygen levels and terrain.\n",
    "- **Fire Mask Features (`FireMask`, `PrevFireMask`)**: Indicate whether there were past or present wildfires in a given area, helping models track fire movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3442e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TFRecord Files: ['/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_00.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_01.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_02.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_03.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_04.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_05.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_06.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_07.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_08.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_09.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_10.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_11.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_12.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_13.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_train_14.tfrecord']\n",
      "Eval TFRecord Files: ['/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_eval_00.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_eval_01.tfrecord']\n",
      "Test TFRecord Files: ['/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_test_00.tfrecord', '/data/ai_club/fire/next_day_fire_spread_data/next_day_wildfire_spread_test_01.tfrecord']\n",
      "Feature Names: ['vs', 'th', 'population', 'tmmx', 'PrevFireMask', 'elevation', 'sph', 'pr', 'pdsi', 'erc', 'FireMask', 'NDVI', 'tmmn']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 18:45:50.229666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13750 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:60:00.0, compute capability: 7.5\n",
      "2025-02-05 18:45:50.231969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13750 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:61:00.0, compute capability: 7.5\n",
      "2025-02-05 18:45:50.234206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 13750 MB memory:  -> device: 2, name: Tesla T4, pci bus id: 0000:da:00.0, compute capability: 7.5\n",
      "2025-02-05 18:45:50.236306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 13750 MB memory:  -> device: 3, name: Tesla T4, pci bus id: 0000:db:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Schema: {'vs': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'th': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'population': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'tmmx': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'PrevFireMask': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'elevation': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'sph': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'pr': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'pdsi': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'erc': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'FireMask': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'NDVI': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None), 'tmmn': FixedLenFeature(shape=[4096], dtype=tf.float32, default_value=None)}\n",
      "Datasets successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Define dataset directory (not a single file)\n",
    "tfrecord_dir = \"/data/ai_club/fire/next_day_fire_spread_data\"\n",
    "\n",
    "def get_tfrecord_files(prefix):\n",
    "    \"\"\"Retrieve sorted TFRecord file paths matching the given prefix.\"\"\"\n",
    "    return sorted([\n",
    "        os.path.join(tfrecord_dir, f) \n",
    "        for f in os.listdir(tfrecord_dir) \n",
    "        if f.startswith(prefix) and f.endswith(\".tfrecord\")\n",
    "    ])\n",
    "\n",
    "# Automatically get all train, eval, and test files\n",
    "train_tfrecord_files = get_tfrecord_files(\"next_day_wildfire_spread_train_\")\n",
    "eval_tfrecord_files = get_tfrecord_files(\"next_day_wildfire_spread_eval_\")\n",
    "test_tfrecord_files = get_tfrecord_files(\"next_day_wildfire_spread_test_\")\n",
    "\n",
    "print(\"Train TFRecord Files:\", train_tfrecord_files)\n",
    "print(\"Eval TFRecord Files:\", eval_tfrecord_files)\n",
    "print(\"Test TFRecord Files:\", test_tfrecord_files)\n",
    "\n",
    "# Load first record to check feature structure\n",
    "def get_feature_names(tfrecord_files):\n",
    "    \"\"\"Extract feature names from a TFRecord file.\"\"\"\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    for raw_record in raw_dataset.take(1):  # Take first record\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        return list(example.features.feature.keys())  # Extract feature names\n",
    "\n",
    "if train_tfrecord_files:\n",
    "    feature_names = get_feature_names(train_tfrecord_files[0])\n",
    "    print(\"Feature Names:\", feature_names)\n",
    "else:\n",
    "    print(\"No training TFRecords found.\")\n",
    "\n",
    "def get_feature_schema(tfrecord_file):\n",
    "    \"\"\"Retrieve the feature schema from a TFRecord.\"\"\"\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    for raw_record in raw_dataset.take(1):  # Inspect first record\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "        schema = {}\n",
    "        for key, feature in example.features.feature.items():\n",
    "            dtype = feature.WhichOneof(\"kind\")\n",
    "            if dtype == \"float_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([len(feature.float_list.value)], tf.float32)\n",
    "            elif dtype == \"int64_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([len(feature.int64_list.value)], tf.int64)\n",
    "            elif dtype == \"bytes_list\":\n",
    "                schema[key] = tf.io.FixedLenFeature([], tf.string)\n",
    "        return schema\n",
    "\n",
    "if train_tfrecord_files:\n",
    "    feature_schema = get_feature_schema(train_tfrecord_files[0])\n",
    "    print(\"Feature Schema:\", feature_schema)\n",
    "else:\n",
    "    print(\"No training TFRecords found.\")\n",
    "\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    \"\"\"Parse a TFRecord using the extracted feature schema.\"\"\"\n",
    "    parsed_features = tf.io.parse_single_example(example_proto, feature_schema)\n",
    "\n",
    "    # Assuming each feature is a 64x64 grid, reshape accordingly\n",
    "    cnn_input = tf.stack([\n",
    "        tf.reshape(parsed_features['FireMask'], [64, 64]),\n",
    "        tf.reshape(parsed_features['NDVI'], [64, 64]),\n",
    "        tf.reshape(parsed_features['PrevFireMask'], [64, 64])\n",
    "    ], axis=-1)  # Shape: (64, 64, 3)\n",
    "\n",
    "    # No LSTM input needed for spatial data\n",
    "    dense_input = tf.stack([\n",
    "        parsed_features.get('vs', tf.constant(0.0)), \n",
    "        parsed_features.get('tmmx', tf.constant(0.0)), \n",
    "        parsed_features.get('tmmn', tf.constant(0.0))\n",
    "    ], axis=-1)\n",
    "\n",
    "    # Reshape target to match model output\n",
    "    target = tf.reduce_mean(parsed_features['FireMask'])  # Example: reduce to a single value\n",
    "\n",
    "    return {'cnn_input': cnn_input, 'dense_input': dense_input}, target\n",
    "\n",
    "def load_dataset(filenames, batch_size=32):\n",
    "    \"\"\"Load and prepare the TFRecord dataset.\"\"\"\n",
    "    if not filenames:\n",
    "        print(\"Warning: No files provided for dataset loading.\")\n",
    "        return None\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = load_dataset(train_tfrecord_files)\n",
    "eval_dataset = load_dataset(eval_tfrecord_files)\n",
    "test_dataset = load_dataset(test_tfrecord_files)\n",
    "\n",
    "print(\"Datasets successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py:642: UserWarning: Input dict contained keys ['dense_input'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n",
      "2025-02-05 18:45:59.892489: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:467] Loaded cuDNN version 90100\n",
      "2025-02-05 18:46:02.661472: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f8074d47b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-02-05 18:46:02.661541: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-02-05 18:46:02.661553: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "2025-02-05 18:46:02.661561: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5\n",
      "2025-02-05 18:46:02.661568: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5\n",
      "2025-02-05 18:46:02.678089: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738799162.821403 1320841 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    469/Unknown - 20s 13ms/step - loss: 1.0111 - accuracy: 0.0017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 18:46:10.973357: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 1891445747162099651\n",
      "2025-02-05 18:46:10.973461: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10182094178111851252\n",
      "2025-02-05 18:46:10.973510: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10600401745972727462\n",
      "2025-02-05 18:46:10.973522: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 14196073620139872227\n",
      "2025-02-05 18:46:10.973541: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18079622383691302428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 20s 14ms/step - loss: 1.0111 - accuracy: 0.0017\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 5s 8ms/step - loss: 1.0390 - accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "206/469 [============>.................] - ETA: 1s - loss: 1.0393 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Define CNN Model\n",
    "cnn_input = Input(shape=(64, 64, 3), name=\"cnn_input\")  # Adjust shape based on your data\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\")(cnn_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=cnn_input, outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_loss, eval_accuracy = model.evaluate(eval_dataset)\n",
    "print(f\"Evaluation Loss: {eval_loss}, Evaluation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
